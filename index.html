<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title></title>
</head>
<body>
  <video id="video" width="1080" height="720"></video>
  <input id="file" type="file">
  <a id="download">Download</a>
  <script>
    const worker = new Worker('worker.js')
    const file = document.getElementById('file');

    let audioContext = new (AudioContext || WebkitAudioContext)()
    let analyser = audioContext.createAnalyser()
    let recorderDestination = audioContext.createMediaStreamDestination()
    let audioFile, audioUrl, source
    let visualizer = document.createElement('canvas')
    let scale = window.devicePixelRatio
    visualizer.width = Math.floor(1080 * scale)
    visualizer.height = Math.floor(720 * scale)
    let context = visualizer.getContext('2d')
    // setup the static areas of the video
    context.fillStyle = 'rgb(0,0,0)'
    context.fillRect(0, 0, visualizer.width, visualizer.height)
    context.fillStyle = 'rgb(255,255,255)'
    context.font = '120px serif'
    context.fillText('treasurer', 50, 120)

    function readFile(file, callback) {
      let reader = new FileReader(file)
      reader.onload = function (e) { callback(e.target.result) }
      reader.readAsArrayBuffer(file)
    }

    let stopped = false
    worker.addEventListener('message', async (e) => {
      if (e.data.image) {
        let width = 4 * visualizer.height / 5
        let bitmap = await createImageBitmap(e.data.image, {
          resizeWidth: width,
          resizeHeight: width
        })
        context.drawImage(
          bitmap,
          visualizer.width/2 - bitmap.width/2,
          visualizer.height/2 - bitmap.height/2)
      }

      if (!stopped) {
        let fft = new Uint8Array(analyser.frequencyBinCount)
        analyser.getByteFrequencyData(fft)
        worker.postMessage({
          fft: fft,
          duration: source.buffer?.duration,
          position: source.context.currentTime
        })
      }
    })

    file.addEventListener('change', event => {
      audioFile = event.target.files[0]

      readFile(audioFile, (buffer) => {
        audioContext.decodeAudioData(buffer, (audioBuffer) => {
          recorder.start(audioBuffer.duration * 1000)
          source.buffer = audioBuffer
          source.start()
          video.play()
        })
      })

      source = audioContext.createBufferSource()
      source.connect(analyser)
      source.connect(audioContext.destination)
      source.connect(recorderDestination)
      
      let canvas = new OffscreenCanvas(
        visualizer.height,
        visualizer.height,
      )
      worker.postMessage({ scale, canvas }, [canvas])
    })

    let stream = visualizer.captureStream()
    let video = document.getElementById('video')
    video.srcObject = stream

    let chunks = []

    let recorder = new MediaRecorder(new MediaStream([
      stream.getVideoTracks()[0],
      recorderDestination.stream.getAudioTracks()[0]
    ]),{
      mimeType: 'video/webm'
    })

    recorder.ondataavailable = function (event) {
      chunks.push(event.data)

      console.log(recorder.state)

      if (recorder.state === 'recording')
        recorder.stop()
    }

    recorder.onstop = function(event) {
      stopped = true
      let blob = new Blob(chunks, { type: 'video/webm' })
      let url = URL.createObjectURL(blob)
      let a = document.getElementById('download')
      a.download = `${audioFile.name}.webm`
      a.href = url
    }

    file.addEventListener('click', () => this.value = "")
  </script>
</body>
</html>

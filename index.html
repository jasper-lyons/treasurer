<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title></title>
</head>
<body>
  <video id="video"></video>
  <input id="file" type="file">
  <a id="download">Download</a>
  <script>
    const worker = new Worker('worker.js')
    const file = document.getElementById('file');

    let audioContext = new (AudioContext || WebkitAudioContext)()
    let analyser = audioContext.createAnalyser()
    let recorderDestination = audioContext.createMediaStreamDestination()
    let audioFile, audioUrl, source
    let visualizer = document.createElement('canvas')
    visualizer.width = 1080
    visualizer.height = 720
    let context = visualizer.getContext('2d')

    function readFile(file, callback) {
      let reader = new FileReader(file)
      reader.onload = function (e) { callback(e.target.result) }
      reader.readAsArrayBuffer(file)
    }

    let stopped = false
    worker.addEventListener('message', async (e) => {
      if (e.data.image) {
        let width = 4 * e.data.image.width / 5
        let height = 4 * e.data.image.height / 5
        let bitmap = await createImageBitmap(e.data.image, {
          resizeWidth: width,
          resizeHeight: height
        })
        context.fillRect(0, 0, visualizer.width, visualizer.height)
        context.drawImage(bitmap, visualizer.width/2 - bitmap.width/2, visualizer.height/2 - bitmap.height/2)
      }

      if (!stopped) {
        let fft = new Uint8Array(analyser.frequencyBinCount)
        analyser.getByteFrequencyData(fft)
        worker.postMessage({
          fft: fft,
          duration: source.buffer?.duration,
          position: source.context.currentTime
        })
      }
    })

    file.addEventListener('change', event => {
      audioFile = event.target.files[0]

      readFile(audioFile, (buffer) => {
        audioContext.decodeAudioData(buffer, (audioBuffer) => {
          recorder.start(audioBuffer.duration * 1000)
          source.buffer = audioBuffer
          source.start()
          video.play()
        })
      })

      source = audioContext.createBufferSource()
      source.connect(analyser)
      source.connect(audioContext.destination)
      source.connect(recorderDestination)

      
      let canvas = new OffscreenCanvas(visualizer.width, visualizer.height)
      worker.postMessage({ canvas }, [canvas])
    })

    let stream = visualizer.captureStream()
    let video = document.getElementById('video')
    video.srcObject = stream

    let chunks = []

    let recorder = new MediaRecorder(new MediaStream([
      stream.getVideoTracks()[0],
      recorderDestination.stream.getAudioTracks()[0]
    ]),{
      mimeType: 'video/webm'
    })

    recorder.ondataavailable = function (event) {
      chunks.push(event.data)

      if (recorder.state === 'recording')
        recorder.stop()
    }

    recorder.onstop = function(event) {
      stopped = true
      let blob = new Blob(chunks, { type: 'video/webm' })
      let url = URL.createObjectURL(blob)
      let a = document.getElementById('download')
      a.download = `${audioFile.name}.webm`
      a.href = url
    }

    file.addEventListener('click', () => this.value = "")
  </script>
</body>
</html>
